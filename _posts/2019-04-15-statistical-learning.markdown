---
layout: post
title:  "统计学习方法"
date:   2019-04-15 12:22:26 +0800
categories: jekyll update
excerpt: 统计学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科，又称统计机器学习。
---

## 统计学习方法概论 
### 统计学习  
统计学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科，又称统计机器学习。  
  
特点：  
* 平台——计算机及网络；  
* 研究对象——数据；  
* 目的——对数据（特别是未知数据）进行预测与分析；  
* 方法——构建模型并应用模型进行预测与分析；
* 概率论、统计学、信息论、计算理论、最优化理论及计算机科学交叉学科。  
  
统计学习的对象是数据，数据$\rightarrow$提取特征$\rightarrow$抽象模型$\rightarrow$分析预测  
统计学习关于数据的基本假设是同类数据具有一定的统计规律性，这是统计学习的前提。  
  
统计学习由监督学习（supervised learning）、非监督学习（unsupervised learning）、半监督学习（semi-supervised learning）和强化学习（reinforcement learning）等组成。  
  
监督学习：从给定的、有限的、用于学习的训练数据（traning data）集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于摸个函数的集合，称为假设空间（hypothesis space）；应用某个评价准则（evaluation criterion），从假设空间中选取一个最优的模型，使它对已知的训练数据及未知测试数据（test data）在给定的评价准则下有最优化的预测；最优模型的选取由算法实现。  
统计学习方法三要素：模型（model）、策略（strategy）和算法（algorithm）。  
实现统计学习方法的步骤：  
1. 得到一个有限的训练数据集合；
2. 确定包含所有可能的模型的假设空间，即学习模型的集合；
3. 确定模型选择地准则，即学习策略；
4. 实现求解最优模型地算法，即学习的算法；
5. 通过学习方法选择最优模型；
6. 利用学习地最优模型对数据进行预测或分析。  
  
### 监督学习  
监督学习地任务是学习一个模型，使模型能够对任意给定地输入，对其相应地输出做一个好的预测。   
输入/输出空间（input/output space）：输入和输出所有可能取值地集合。  
每个具体地输入是一个实例（instance），通常由特征向量（feature vector）表示，所有特征向量存在地空间称为特征空间（feature space）。  
输入、输出变量用大写字母表示，其所取地值用小写字母表示。  
输入实例x的特征向量记作 $x=(x^{(1)},x^{(2)},\cdots,x^{(i)},\cdots,x^{(n)})^{T}$  ，$x^{(i)}$表示x的第i个特征。
训练集通常表示为 $T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}$，输入与输出对$(x_i,y_i), i=1,2,\cdots,N$又称为样本（sample）或样本点。  
根据输入、输出变量的不同类型，预测任务有不同的名称：
* 输入与输出变量均为连续变量的预测问题称为回归问题；
* 输出变量为有限个离散变量的预测问题称为分类问题；
* 输入与输出变量均为变量序列的预测问题称为标注问题。

监督学习假设输入与输出的随机变量X和Y遵循联合概率分布$P(X,Y)$，$P(X,Y)$表示分布函数，或分布密度函数。  
假设空间是输入空间到输出空间的映射的集合。  
监督学习的模型可以是概率模型或非概率模型，由条件概率分布$P(Y|X)$或决策函数$Y=f(X)$表示。  
监督学习分为学习和预测两个过程，由学习系统与预测系统完成。  
### 统计学习三要素
#### 模型
在监督学习中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间包含所有可能的条件概率分布或决策函数。由决策函数表示的模型称为非概率模型，由条件概率表示的模型称为概率模型。  
假设空间用$\mathcal{F}$表示，假设空间可以定义为决策函数/条件概率的集合  
$\mathcal{F}=\{f|Y=f(X)\}$
$\mathcal{F}=\{P|P(Y|X)\}$
其中，X和Y是定义在输入空间$\mathcal{X}$和输出空间$\mathcal{Y}$上的变量/随机变量，这时$\mathcal{F}$通常是由一个参数向量决定的函数族/条件概率分布族  
$\mathcal{F}=\{f|Y=f_{\theta}(X)\},\theta\in \mathbf{R}^{n}$
$\mathcal{F}=\{P|P_{\theta}(Y|X)\},\theta\in \mathbf{R}^{n}$
参数向量$\theta$取值于n维欧氏空间$\mathbf{R}^{n}$，也称参数空间。  
#### 策略
##### 损失函数和风险函数
在监督学习问题中用一个损失函数（loss function）或代价函数（cost function）来度量预测错误的程度。  
损失函数是$f(X)$和Y的非负实值函数，记作$L(Y,f(X))$，常用的损失函数有  
* 0-1损失函数  
$$ L(Y,f(X))=
\begin{cases}
1,Y\neq f(X)\\
0,Y= f(X)
\end{cases}$$  
* 平方损失函数  
$$L(Y,f(X))=(Y-f(X))^2$$  
* 绝对损失函数  
$$L(Y,f(X))=|Y-f(X)|$$  
* 对数损失函数  
$$L(Y,f(X))=-\log P(Y|X)$$  
  
由于模型的输入、输出$(X,Y)$是随机变量，遵循联合分布$P(Y|X)$，所以损失函数的期望是  
$$R_{exp}=E_{P}[L(Y,f(X))]=\int_{\mathcal{X}\times\mathcal{Y}}L(y,f(x))P(x,y)dxdy$$  
这是理论上模型$f(X)$关于联合分布P(X,Y)的平均意义下的损失，称为风险函数（risk function）或期望损失（expected loss）。  